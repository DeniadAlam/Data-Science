# Data-Science

# ğŸ“Š Introduction to Data Science Final Project â€“ Group 03  
**Introduction to Data Science** â€“ Spring 2024-2025  
**American International University-Bangladesh (AIUB)**  
**Course Teacher:** Dr. Abdus Salam  
**Section:** E  

## ğŸ‘¥ Group Members
| Serial | Name                | ID           |
|--------|---------------------|--------------|
| 01     | Md. Ashfaq Bin Hoque | 22-46662-1 |
| 02     | Md. Deniad Alam      | 22-46658-1 |
| 03     | Maruf Billah Siddiki | 22-47177-1 |
| 04     | Al Fahim             | 22-46402-1 |

---

## ğŸ“ Project Overview

This project performs **web scraping**, **text preprocessing**, and **topic modeling** on real news articles sourced from the **Dhaka Tribune** website. The aim is to identify hidden topics in the news content using **Latent Dirichlet Allocation (LDA)**.

---

## ğŸ“¦ Technologies & Libraries

**Language:** R  
**Key Libraries:**
- `rvest`, `RSelenium`, `dplyr`, `tm`, `textstem`, `textclean`, `stopwords`, `tidytext`, `topicmodels`, `knitr`, `reshape2`, `stringr`

---

## ğŸ•¸ï¸ Part 1: Web Scraping

### âœ… Steps:
1. **AJAX Handling:**  
   Using `RSelenium` to simulate â€œLoad Moreâ€ button clicks with `clickAjaxButton()`

2. **Helper Functions:**  
   - `get_title()`, `get_content()`, `get_date()`

3. **Scraping Categories:**  
   - Sports, Politics, Entertainment, Foreign Affairs, Elections

4. **Final Output:**  
   - A combined CSV file containing titles, dates, categories, and article contents from 5 sections of the news site.

---

## ğŸ§¹ Part 2: Text Preprocessing

### âœ… Techniques Used:
- **Emoji Replacement**
- **Contraction Expansion**
- **Lowercasing**
- **Dash & Punctuation Removal**
- **Whitespace Normalization**
- **Tokenization**
- **Stopword Removal**
- **Lemmatization**
- **Numeric Token Removal**

### âœ… Output:
A cleaned version of the dataset saved to CSV, ready for analysis.

---

## ğŸ” Part 3: Topic Modeling (LDA)

### âœ… LDA Workflow:
1. Convert cleaned text into **Document-Term Matrix (DTM)**
2. Apply **Latent Dirichlet Allocation** with `k = 10` topics
3. Extract:
   - **Top 10 terms per topic** (based on Î²)
   - **Topic proportions per document** (based on Î³)

### ğŸ§  Example Topics:
- **Topic 2**: film, director, story â†’ Entertainment  
- **Topic 4**: election, commission, reform â†’ Politics/Elections  
- **Topic 7**: india, pakistan, cricket â†’ International Cricket

---

## ğŸ“ˆ Results & Interpretation

- **Î² (Beta values)** show strong associations between keywords and topics.
- **Î³ (Gamma values)** indicate dominant topics per article.
- Clear distinction found between categories like politics, sports, and entertainment.

---

## ğŸ“ Project Structure

```text
ğŸ“¦ ids_final_project_group_03/
â”œâ”€â”€ scraping/
â”‚   â”œâ”€â”€ 01_load_libraries.R             # Load required libraries for scraping
â”‚   â”œâ”€â”€ 02_click_ajax_button.R         # Simulate "Load More" button clicks
â”‚   â”œâ”€â”€ 03_helper_functions.R          # get_title(), get_content(), get_date()
â”‚   â”œâ”€â”€ 04_scrape_category.R           # Scrape a single news category
â”‚   â”œâ”€â”€ 05_launch_selenium.R           # Set up Firefox driver with RSelenium
â”‚   â”œâ”€â”€ 06_scrape_multiple_categories.R# Scrape 5 categories from Dhaka Tribune
â”‚   â”œâ”€â”€ 07_combine_and_save.R          # Combine and save raw data to CSV
â”‚   â”œâ”€â”€ 08_close_browser.R             # Close browser and Selenium server
â”‚   â””â”€â”€ raw_data.csv                   # Output: All scraped articles
â”‚
â”œâ”€â”€ preprocessing/
â”‚   â”œâ”€â”€ 01_load_libraries.R            # Load libraries for text preprocessing
â”‚   â”œâ”€â”€ 02_preprocessing_functions.R  # Clean, tokenize, lemmatize, etc.
â”‚   â”œâ”€â”€ 03_run_pipeline.R             # Apply preprocessing pipeline
â”‚   â””â”€â”€ cleaned_data.csv              # Output: Cleaned/preprocessed text data
â”‚
â”œâ”€â”€ topic_modeling/
â”‚   â”œâ”€â”€ 01_load_libraries.R           # Load libraries for topic modeling
â”‚   â”œâ”€â”€ 02_data_loading.R             # Load cleaned CSV into a corpus
â”‚   â”œâ”€â”€ 03_create_dtm.R               # Create Document-Term Matrix
â”‚   â”œâ”€â”€ 04_run_lda.R                  # Apply LDA (k = 10 topics)
â”‚   â”œâ”€â”€ 05_extract_topics.R           # Extract top terms per topic
â”‚   â”œâ”€â”€ 06_topic_probabilities.R      # Document-topic gamma values
â”‚   â””â”€â”€ topic_model_results.csv       # Output: Top terms and topic weights
â”‚
â”œâ”€â”€ figures/                          # Optional: Save any plots/tables
â”‚   â”œâ”€â”€ top_terms_table.png
â”‚   â””â”€â”€ topic_distributions.png
â”‚
â”œâ”€â”€ data/                             # Backup or supporting data files
â”‚   â””â”€â”€ dhakatribune_urls.txt
â”‚
â””â”€â”€ README.md                         # Project summary and documentation

```




---

## ğŸš€ How to Run (Locally)
1. Clone this repo
2. Install required R packages
3. Run `scraping/scrape_functions.R`
4. Run `preprocessing/text_cleaning_pipeline.R`
5. Run `topic_modeling/lda_model.R` to generate topics

---

## ğŸ Final Notes
This project demonstrates real-world **data acquisition**, **natural language processing**, and **unsupervised learning** using R.  
Feel free to explore, reuse, or expand the analysis.

---

## ğŸ“œ License
This project is for academic use under AIUB's course guidelines.


